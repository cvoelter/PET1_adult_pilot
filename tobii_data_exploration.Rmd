---
title: "Tobii data processing"
output: html_document
date: "2025-07-27"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Load required packages
library(tidyverse)
library(readr)
library(ggplot2)
library(lubridate)
library(lme4)
library(naniar)
library(gazer)
library(zoo)
library(arrow)

```
# Loading video data
```{r}
## time_frame for interpolation
max.time <- 38600
min.time <- 0
time_frame <- seq(from = min.time, to = max.time, by = 1)
xx <- as.data.frame(time_frame)
# baseline.start<-0
# baseline.end<-3000
# start_ip <- 3000
video.data <- read_csv("data/PET_adult_pilot_video_list.csv")%>%
  mutate(video_file = str_remove(video_file, fixed(".mp4")))%>%
  filter(experiment!="attention_check")
video.data_variable_names <- colnames(video.data)
```

```{r}
# Read the TSV file

eye_data <- read_tsv("data/PET_network_study1_Ngamba_Data_Export_incl_AOIs.tsv",
                     na = c("", "NA", "N/A")) %>%
  rename_with( ~ gsub(" ", "_", .x)) %>%
  filter(
    Presented_Stimulus_name %in% c(
      "continuity_ver1_n_cont",
      "continuity_ver1_n_test",
      "continuity_ver2_n_cont",
      "continuity_ver2_n_test",
      "gravity_ver1_n_cont",
      "gravity_ver1_n_test",
      "gravity_ver2_n_cont",
      "gravity_ver2_n_test",
      "solidity_ver1_n_cont",
      "solidity_ver1_n_test",
      "solidity_ver2_n_cont",
      "solidity_ver2_n_test"
    )
  )
```

```{r}
eye_data <- eye_data %>%
  mutate(
    experiment = str_extract(Presented_Stimulus_name, "^[^_]+"),                   # text before first underscore
    version = str_extract(Presented_Stimulus_name, "ver[0-9]+"),                  # ver and digit(s)
    experiment_version = str_c(experiment, "_", version),                            # combine for e.g. continuity_ver1
    condition = if_else(str_detect(Presented_Stimulus_name, "_cont$"), "cont", "test"),
    subject = Participant_name,
    video_file = Presented_Stimulus_name
  ) %>%
  rename(
    #Gravity Ver 1

    'AOI_hit_gravity_ver1_cont_apple'  = 'AOI_hit_[gravity_ver1_n_cont_-_Ellipse]',
    'AOI_hit_gravity_ver1_test_apple' = 'AOI_hit_[gravity_ver1_n_test_-_Ellipse]',

    'AOI_hit_gravity_ver1_cont_whole_screen'  = 'AOI_hit_[gravity_ver1_n_cont_-_Gravity_Ver1_WholeScreen]',
    'AOI_hit_gravity_ver1_test_whole_screen' = 'AOI_hit_[gravity_ver1_n_test_-_Gravity_Ver1_WholeScreen]',

    'AOI_hit_gravity_ver1_cont_supr_event'  = 'AOI_hit_[gravity_ver1_n_cont_-_Polygon]',
    'AOI_hit_gravity_ver1_test_supr_event' = 'AOI_hit_[gravity_ver1_n_test_-_Polygon]',

    #Gravity Ver 2

    'AOI_hit_gravity_ver2_cont_apple' = 'AOI_hit_[gravity_ver2_n_cont_-_Ellipse]',
    'AOI_hit_gravity_ver2_test_apple' = 'AOI_hit_[gravity_ver2_n_test_-_Ellipse]',

    'AOI_hit_gravity_ver2_cont_whole_screen' = 'AOI_hit_[gravity_ver2_n_cont_-_Gravity_Ver2_WholeScreen]',
    'AOI_hit_gravity_ver2_test_whole_screen' = 'AOI_hit_[gravity_ver2_n_test_-_Gravity_Ver2_WholeScreen]',

    'AOI_hit_gravity_ver2_cont_supr_event' = 'AOI_hit_[gravity_ver2_n_cont_-_Polygon]',
    'AOI_hit_gravity_ver2_test_supr_event' = 'AOI_hit_[gravity_ver2_n_test_-_Polygon]',

    #Solidity Ver 1

    'AOI_hit_solidity_ver1_cont_apple'  = 'AOI_hit_[solidity_ver1_n_cont_-_Ellipse]',
    'AOI_hit_solidity_ver1_test_apple'  = 'AOI_hit_[solidity_ver1_n_test_-_Ellipse]',

    'AOI_hit_solidity_ver1_cont_supr_event'  = 'AOI_hit_[solidity_ver1_n_cont_-_Polygon]',
    'AOI_hit_solidity_ver1_test_supr_event'  = 'AOI_hit_[solidity_ver1_n_test_-_Polygon_1]',

    'AOI_hit_solidity_ver1_cont_whole_screen'  = 'AOI_hit_[solidity_ver1_n_cont_-_Solidity_Ver1_WholeScreen]',
    'AOI_hit_solidity_ver1_test_whole_screen'  = 'AOI_hit_[solidity_ver1_n_test_-_Solidity_Ver1_WholeScreen]',

    #Solidity Ver 2

    'AOI_hit_solidity_ver2_cont_apple' = 'AOI_hit_[solidity_ver2_n_cont_-_Ellipse]',
    'AOI_hit_solidity_ver2_test_apple' = 'AOI_hit_[solidity_ver2_n_test_-_Ellipse]',

    'AOI_hit_solidity_ver2_cont_supr_event' = 'AOI_hit_[solidity_ver2_n_cont_-_Rectangle]',
    'AOI_hit_solidity_ver2_test_supr_event' = 'AOI_hit_[solidity_ver2_n_test_-_Rectangle_2]',

    # 'AOI_hit_solidity_ver2_cont_supr_event' = 'AOI_hit_[solidity_ver2_n_cont_-_Rectangle_2]',
    # 'AOI_hit_solidity_ver2_test_supr_event' = 'AOI_hit_[solidity_ver2_n_test_-_Rectangle_2]',

    'AOI_hit_solidity_ver2_cont_whole_screen' = 'AOI_hit_[solidity_ver2_n_cont_-_Solidity_Ver2_WholeScreen]',
    'AOI_hit_solidity_ver2_test_whole_screen' = 'AOI_hit_[solidity_ver2_n_test_-_Solidity_Ver2_WholeScreen]',
    

    #Continuity Ver 1

    'AOI_hit_continuity_ver1_cont_apple' = 'AOI_hit_[continuity_ver1_n_cont_-_Ellipse]',
    'AOI_hit_continuity_ver1_test_apple' = 'AOI_hit_[continuity_ver1_n_test_-_Ellipse]',

    # here I two rectangles, but for each video, but there should only ne one_ I need to check which one is correct_
    # For now I chose the AOIs that have more hits (since we made it larger)
    # Please be aware in the analysis that this might still change when I can check the Tobii project

    'AOI_hit_continuity_ver1_cont_supr_event_left' = 'AOI_hit_[continuity_ver1_n_cont_-_Rectangle_2]',
    'AOI_hit_continuity_ver1_cont_supr_event_right' = 'AOI_hit_[continuity_ver1_n_cont_-_Rectangle_1]',
    'AOI_hit_continuity_ver1_test_supr_event_left' = 'AOI_hit_[continuity_ver1_n_test_-_Rectangle]',
    'AOI_hit_continuity_ver1_test_supr_event_right' = 'AOI_hit_[continuity_ver1_n_test_-_Rectangle_1]',

    'AOI_hit_continuity_ver1_cont_whole_screen'  = 'AOI_hit_[continuity_ver1_n_cont_-_Cont_Ver1_WholeScreen]',
    'AOI_hit_continuity_ver1_test_whole_screen' = 'AOI_hit_[continuity_ver1_n_test_-_Cont_Ver1_WholeScreen]',
    
    #Continuity Ver 2

    'AOI_hit_continuity_ver2_cont_apple' = 'AOI_hit_[continuity_ver2_n_cont_-_Ellipse]',
    'AOI_hit_continuity_ver2_test_apple' = 'AOI_hit_[continuity_ver2_n_test_-_Ellipse]',

    'AOI_hit_continuity_ver2_cont_supr_event' = 'AOI_hit_[continuity_ver2_n_cont_-_Rectangle_1]',
    'AOI_hit_continuity_ver2_test_supr_event' = 'AOI_hit_[continuity_ver2_n_test_-_Rectangle_1]',

    'AOI_hit_continuity_ver2_cont_whole_screen' = 'AOI_hit_[continuity_ver2_n_cont_-_Cont_Ver2_WholeScreen]',
    'AOI_hit_continuity_ver2_test_whole_screen' = 'AOI_hit_[continuity_ver2_n_test_-_Cont_Ver2_WholeScreen]',

  )

```

```{r}

unique(eye_data$subject)
unique(eye_data$video_file)
length(unique(eye_data$subject))

```

```{r}
sample_data <- eye_data %>%
  full_join(video.data) %>%
  #inner_join(demo.data)%>%
  select(
    RECORDING_SESSION_LABEL = Recording_name,
    subject,
    experiment,
    condition,
    version,
    experiment_version,
    video_file,
    Timeline_name,
    Eyetracker_timestamp,
    Recording_timestamp,
    Eye_movement_type,
    Eye_movement_type_index,
    Gaze_event_duration, 
    starts_with("AOI_hit_"),
    starts_with("Gaze_point_"),
    starts_with("Pupil_diameter"),
    all_of(video.data_variable_names),
    Validity_left,
    Validity_right
  )
```
# Define interest periods

* create time variable
```{r}
sample_data <- sample_data %>%
  group_by(subject, video_file, RECORDING_SESSION_LABEL) %>%
  mutate(
    time_frame = (Recording_timestamp - min(Recording_timestamp, na.rm=TRUE))/1000
  ) %>%
  ungroup

sample_data_example <- sample_data %>%
  filter(subject == "Asega", video_file == "gravity_ver2_n_test", RECORDING_SESSION_LABEL =="Recording191")

library(arrow)
write_csv(sample_data_example, "data/chimp_example_data.csv")

```

* create IPs
```{r}
fixation_data <- sample_data %>%
  group_by(subject, video_file, RECORDING_SESSION_LABEL, Eye_movement_type_index) %>%
  slice(1) %>%  # keeps the first row per group (you could use summarise if you want to e.g. sum duration across possible splits)
  ungroup() %>%
  mutate(
    end_state_IP = time_frame >= duration,
    object_moving_IP = time_frame >= IP_test_event_start & time_frame < duration,
    whole_test_event_IP = time_frame >= IP_test_event_start
  )
```

* Extract the relevant AOI columns
```{r}
library(stringr)

# Create an AOI pattern for each row (per experiment, version, condition)
fixation_data <- fixation_data %>%
  mutate(
    aoi_prefix = paste0("AOI_hit_[", experiment, "_", version, "_", condition)
  )
#from tobii manual:  hit Reports whether the AOI is active and whether the fixation is located inside of the AOI: -1 = AOI not active; 0 = AOI active, the fixation is not located in the AOI; 1 = AOI active and the fixation is located inside of the AOI; empty cell indicates that the media of the AOI was not visible.
aoi_cols <- fixation_data %>% 
  dplyr::select(starts_with("AOI_hit_")) %>%
  colnames()

library(tidyr)
library(purrr)

# Pivot AOIs to long format for easier aggregation
fixation_data_long <- fixation_data %>%
  pivot_longer(
    cols = starts_with("AOI_hit_"),
    names_to = "AOI",
    values_to = "aoi_hit"
  ) %>%
  filter(str_detect(
    AOI,
    fixed(paste0(experiment, "_", version, "_", condition))
  ))

levels(as.factor(fixation_data_long$AOI))

```


```{r}


# Only where gaze is in AOI and fixation was detected
looking_times_long <- fixation_data_long %>%
  filter(aoi_hit == 1)%>%#, Eye_movement_type == "Fixation") %>%
  group_by(subject, experiment, version, condition, AOI) %>%
  summarise(
    looking_time_end_state        = sum(Gaze_event_duration[end_state_IP], na.rm = TRUE),
    looking_time_object_moving    = sum(Gaze_event_duration[object_moving_IP], na.rm = TRUE),
    looking_time_whole_test_event = sum(Gaze_event_duration[whole_test_event_IP], na.rm = TRUE),
    .groups = "drop"
  )

levels(as.factor(looking_times_long$AOI))
```


```{r}
library(dplyr)
library(stringr)
library(ggplot2)
library(gghalves)

# Choose your analysis parameters
experiment      <- "continuity"
version         <- "ver2"
aoi_suffix      <- "whole_screen"        # Or "apple", "supr_event", etc.
ip_column       <- "looking_time_end_state"   # Or "looking_time_object_moving" etc.

# Get relevant AOI names for both conditions
aois <- c(
  paste0("AOI_hit_", experiment, "_", version, "_cont_", aoi_suffix),
  paste0("AOI_hit_", experiment, "_", version, "_test_", aoi_suffix)
)

# Filter just these AOIs and tidy up
aoi_data <- looking_times_long %>%
  filter(AOI %in% aois) %>%
  mutate(
    condition = if_else(str_detect(AOI, "_cont_"), "cont", "test")  # ensures correct grouping
  ) %>%
  select(subject, condition, dwell_time = all_of(ip_column))        # rename for convenience

table(aoi_data$condition)

aoi_data_wide <- aoi_data %>%
  tidyr::pivot_wider(names_from = condition, values_from = dwell_time) %>%
    filter(!is.na(cont), !is.na(test))


plot_data <- aoi_data_wide %>%
  tidyr::pivot_longer(c(cont, test), names_to = "condition", values_to = "dwell_time") %>%
  mutate(
    condition2 = jitter(as.numeric(as.factor(condition)), amount = .1)
  )

t_test_result <- t.test(aoi_data_wide$cont, aoi_data_wide$test, paired = TRUE)
p_value <- t_test_result$p.value
mean_test <- mean(aoi_data_wide$test)
mean_cont <- mean(aoi_data_wide$cont)


y_lim_min = 0
y_lim_max = max(plot_data$dwell_time, na.rm=TRUE) * 1.1

plot <- ggplot(data = plot_data, aes(x = as.numeric(as.factor(condition)), y = dwell_time)) +
  geom_point(aes(x = condition2, color = condition), size = 1.5, alpha = .5) +
  geom_line(aes(group = subject), color = 'lightgray', alpha = .5) +
  geom_half_boxplot(
    data = plot_data %>% filter(condition == "test"),
    aes(x = condition2, y = dwell_time),
    position = position_nudge(x = .25),
    side = "r",
    outlier.shape = NA,
    center = TRUE,
    errorbar.draw = TRUE,
    width = .1,
    fill = 'darkorange',
    alpha = .5,
    inherit.aes = FALSE
  ) +
  geom_half_boxplot(
    data = plot_data %>% filter(condition == "cont"),
    aes(x = condition2, y = dwell_time),
    position = position_nudge(x = -0.4),
    side = "r",
    outlier.shape = NA,
    center = TRUE,
    errorbar.draw = TRUE,
    width = .1,
    fill = 'dodgerblue',
    alpha = .5,
    inherit.aes = FALSE
  ) +
  annotate(
    "text",
    x = 1.5,
    y = y_lim_max - (y_lim_max-y_lim_min)/20,
    label = paste("p =", formatC(p_value, digits = 2)),
    size = 5,
    color = "black"
  ) +
  scale_x_continuous(
    breaks = c(1, 2),
    labels = c("Control", "Test"),
    limits = c(0.4, 2.5)
  ) +
  xlab("Condition") + ylab("Dwell time (ms)") +
  theme_classic() +
  coord_cartesian(ylim = c(y_lim_min, y_lim_max))

plot
```
```{r}
library(dplyr)
library(stringr)
library(ggplot2)
library(gghalves)

# Create output directory if needed
output_dir <- file.path("graphs", "chimp_data", "looking_times")
if (!dir.exists(output_dir)) dir.create(output_dir, recursive = TRUE)

# Get parameter levels directly from your dataset
experiments  <- unique(looking_times_long$experiment)
versions     <- unique(looking_times_long$version)
aoi_suffixes <- c("whole_screen", "apple", "supr_event",  "supr_event_left",  "supr_event_right")
ip_columns   <- c("looking_time_whole_test_event", "looking_time_end_state", "looking_time_object_moving" )

# Function to generate + save plot
make_and_save_plot <- function(experiment, version, aoi_suffix, ip_column) {
  # Build AOI names from parameters
  aois <- c(
    paste0("AOI_hit_", experiment, "_", version, "_cont_", aoi_suffix),
    paste0("AOI_hit_", experiment, "_", version, "_test_", aoi_suffix)
  )

  # Filter data
  aoi_data <- looking_times_long %>%
    filter(
      experiment == !!experiment,
      version == !!version,
      AOI %in% aois
    ) %>%
    mutate(condition = if_else(str_detect(AOI, "_cont_"), "cont", "test")) %>%
    select(subject, condition, dwell_time = all_of(ip_column))

  # Create wide form and ensure both conditions exist
  aoi_data_wide <- aoi_data %>%
    tidyr::pivot_wider(names_from = condition, values_from = dwell_time) 

  if (nrow(aoi_data_wide) == 0) {
    message("Skipping: no usable data for ", paste(experiment, version, aoi_suffix, ip_column, sep = "_"))
    return(NULL)
  }

  # Prepare plot data
  plot_data <- aoi_data_wide %>%
    tidyr::pivot_longer(c(cont, test), names_to = "condition", values_to = "dwell_time") %>%
    mutate(condition2 = jitter(as.numeric(as.factor(condition)), amount = .1))

  # Check if both conditions are present
  unique_conditions <- unique(plot_data$condition)
  if (!all(c("cont", "test") %in% unique_conditions)) {
    message("Skipping: missing condition(s) for ", paste(experiment, version, aoi_suffix, ip_column, sep = "_"))
    return(NULL)
  }

  # Check for non-zero dwell times
  has_non_zero <- plot_data$dwell_time > 0 & !is.na(plot_data$dwell_time)
  if (!any(has_non_zero)) {
    message("Skipping: all dwell times are zero for ", paste(experiment, version, aoi_suffix, ip_column, sep = "_"))
    return(NULL)
  }

  # Perform t-test
  t_test_result <- t.test(aoi_data_wide$cont, aoi_data_wide$test, paired = TRUE)
  p_value <- t_test_result$p.value

  # Set y-axis limits
  y_lim_min <- 0
  y_lim_max <- max(plot_data$dwell_time, na.rm = TRUE) * 1.1

  # Create the plot
  plot <- ggplot(data = plot_data, aes(x = as.numeric(as.factor(condition)), y = dwell_time)) +
    geom_point(aes(x = condition2, color = condition), size = 1.5, alpha = 0.5) +
    geom_line(aes(x= condition2, group = subject), color = 'lightgray', alpha = 0.5)

  # Add half-boxplots with error handling
  test_data <- plot_data %>% filter(condition == "test")
  cont_data <- plot_data %>% filter(condition == "cont")

  if (sum(test_data$dwell_time, na.rm=TRUE) > 0) {
    plot <- plot + geom_half_boxplot(
      data = test_data,
      aes(x = condition2, y = dwell_time),
      position = position_nudge(x = 0.25),
      side = "r",
      outlier.shape = NA,
      center = TRUE,
      errorbar.draw = TRUE,
      width = 0.1,
      fill = 'darkorange',
      alpha = 0.5,
      inherit.aes = FALSE
    )
  }

  if (sum(cont_data$dwell_time, na.rm=TRUE) > 0) {
    plot <- plot + geom_half_boxplot(
      data = cont_data,
      aes(x = condition2, y = dwell_time),
      position = position_nudge(x = -0.4),
      side = "r",
      outlier.shape = NA,
      center = TRUE,
      errorbar.draw = TRUE,
      width = 0.1,
      fill = 'dodgerblue',
      alpha = 0.5,
      inherit.aes = FALSE
    )
  }

  # Annotate the plot
  plot <- plot +
    annotate(
      "text",
      x = 1.5,
      y = y_lim_max - (y_lim_max - y_lim_min) / 20,
      label = paste("p =", formatC(p_value, digits = 2)),
      size = 5,
      color = "black"
    ) +
    scale_x_continuous(
      breaks = c(1, 2),
      labels = c("Control", "Test"),
      limits = c(0.4, 2.5)
    ) +
    xlab("Condition") + ylab("Dwell time (ms)") +
    theme_classic() +
    coord_cartesian(ylim = c(y_lim_min, y_lim_max))+
    scale_color_manual(values = c("cont" = "dodgerblue", "test" = "darkorange"))

  # Save the plot
  file_name <- paste(experiment, version, aoi_suffix, ip_column, sep = "_")
  ggsave(
    filename = file.path(output_dir, paste0(file_name, ".png")),
    plot = plot,
    width = 6, height = 4, dpi = 300
  )

  message("Saved: ", file_name)
}

# Loop over all combinations
for (experiment in experiments) {
  for (version in versions) {
    for (aoi_suffix in aoi_suffixes) {
      for (ip_column in ip_columns) {
        make_and_save_plot(experiment, version, aoi_suffix, ip_column)
      }
    }
  }
}
```





# Pupil size




```{r}
sample_data<-read_parquet("data/PET1_chimp_Ngamba_MAD8.parquet")
```


```{r}
sample_data <- sample_data %>%
  rename(LEFT_PUPIL_SIZE = Pupil_diameter_left,
         RIGHT_PUPIL_SIZE = Pupil_diameter_right,
         LEFT_GAZE_X = Gaze_point_left_X,
         LEFT_GAZE_Y = Gaze_point_left_Y,
         RIGHT_GAZE_X = Gaze_point_right_X,
         RIGHT_GAZE_Y = Gaze_point_right_Y)
```


```{r}
sample_data<- sample_data %>%
  group_by(subject, experiment, version, condition, video_file) %>%
  mutate(
    trial = match(RECORDING_SESSION_LABEL,
                  sort(unique(RECORDING_SESSION_LABEL)))
  ) %>%
  ungroup()



sample_data %>% group_by(subject,
                         experiment,
                         version,
                         condition,
                         video_file,
                         RECORDING_SESSION_LABEL, trial) %>%
  summarise(n = sum(!is.na(Pupil_diameter_filtered)))
```
## Artefact check
*Plot raw data

```{r}
sample_data$video_recording <- paste(sample_data$video_file, sample_data$trial, sep = "_")
# Loop through each level of video_file
unique_videos <- unique(sample_data$video_recording)

for (video in unique_videos) {
  
  # Filter data for the current video file
  video_data <- sample_data %>% filter(video_recording == video, !is.na(subject))
  
  # Create the plot for the current video
  raw_data_plot <- ggplot(data = video_data, aes(x = time_frame, y = LEFT_PUPIL_SIZE)) +
    ylab("Pupil size") +
    xlab("Time (in ms)") +
    geom_point(alpha = 1, size = 0.5, color = "darkorange") +
    geom_point(aes(y = RIGHT_PUPIL_SIZE), alpha = 1, size = 0.5, color = "dodgerblue") +
    facet_wrap(~ subject, ncol = 8, nrow = 5) +   # 8 columns, 5 rows
    theme_bw() +
    scale_color_manual(values=c("darkorange", "dodgerblue")) +
    scale_fill_manual(values=c("darkorange", "dodgerblue")) +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.y = element_blank(),
          legend.title = element_blank(), 
          legend.position = "top", 
          legend.text = element_text(size = 12))
  
  # Save the plot
  ggsave(filename = paste0("graphs/chimp_data/pupil_raw/", video, "_pupil_raw.png"), plot = raw_data_plot, width = 18, height = 12)
}

```




### Artefact correction

```{r}
# NA‑safe version
speed_pupil_safe <- function(pup, time) {
  cur_dilation_speed <- diff(pup) / diff(time)
  backward_pupil <- c(NA, cur_dilation_speed)
  forward_pupil  <- c(cur_dilation_speed, NA)
  backfwd_pupil  <- cbind(backward_pupil, forward_pupil)
  
  # Row‑wise max, return NA if both are NA
  max_backfwd_pupil <- apply(backfwd_pupil, 1, function(r) {
    if (all(is.na(r))) {
      return(NA_real_)
    } else {
      return(max(r, na.rm = TRUE))
    }
  })
  
  return(abs(max_backfwd_pupil))
}

# NA‑safe calc_mad
calc_mad_safe <- function(max_dilation, n = 16) {
  if (all(is.na(max_dilation))) {
    return(NA_real_)  # No valid data for this group
  }
  med_d <- median(max_dilation, na.rm = TRUE)
  mad   <- median(abs(max_dilation - med_d), na.rm = TRUE)
  thres <- med_d + (n * mad)
  return(thres)
}
```

```{r}
sample_data <- sample_data %>%
 # filter(RECORDING_SESSION_LABEL == "Recording4", subject == "Pasa") %>%
  group_by(RECORDING_SESSION_LABEL, subject, experiment, version, condition, video_file) %>%
  mutate(
    # ---- Overall pupil ----
    speed_pupil_all  = speed_pupil_safe(Pupil_diameter_filtered, time_frame),
    MAD_pupil_all    = calc_mad_safe(speed_pupil_all, n = 8),
    pupil.noArtefact = ifelse(
      !is.na(speed_pupil_all) & speed_pupil_all < MAD_pupil_all,
      Pupil_diameter_filtered,
      NA_real_
    ),
    pupil.inter2     = zoo::na.approx(pupil.noArtefact, na.rm = FALSE, maxgap = 100),
    
    # ---- Left pupil ----
    speed_left_pupil = speed_pupil_safe(LEFT_PUPIL_SIZE, time_frame),
    MAD_left_pupil   = calc_mad_safe(speed_left_pupil, n = 8),
    LEFT_pupil.noArtefact = ifelse(
      !is.na(speed_left_pupil) & speed_left_pupil < MAD_left_pupil,
      LEFT_PUPIL_SIZE,
      NA_real_
    ),
    LEFT_pupil.inter2 = zoo::na.approx(LEFT_pupil.noArtefact, na.rm = FALSE, maxgap = 100),
    
    # ---- Right pupil ----
    speed_right_pupil = speed_pupil_safe(RIGHT_PUPIL_SIZE, time_frame),
    MAD_right_pupil   = calc_mad_safe(speed_right_pupil, n = 8),
    RIGHT_pupil.noArtefact = ifelse(
      !is.na(speed_right_pupil) & speed_right_pupil < MAD_right_pupil,
      RIGHT_PUPIL_SIZE,
      NA_real_
    ),
    RIGHT_pupil.inter2 = zoo::na.approx(RIGHT_pupil.noArtefact, na.rm = FALSE, maxgap = 100)
  )





min(sample_data$pupil.inter2, na.rm=TRUE)
max(sample_data$pupil.inter2, na.rm=TRUE)
```


The preprocessing steps conducted in this study aimed to enhance the quality of pupillometry data. Initially, blink artifacts were removed by extending the detected blinks by 100 ms. Subsequently, the speed of pupil diameter changes over time was calculated . Median speed values were then computed for each recording session to serve as a baseline for identifying outliers. Outliers were detected based on the median absolute deviation (MAD) method, with a threshold set at eight times the MAD. Additionally, based on visual inspection of the data we excluded values with leading or lagging NA values within a window of the next 15 entries. Finally, missing values were interpolated using a spline method to ensure the continuity of the pupil size data. Overall, these preprocessing steps aimed to mitigate artifacts and enhance the reliability of the pupillometry dataset for subsequent analyses.

* Plotting of artefact checks


```{r}

unique_videos <- unique(sample_data$video_recording)

for (video in unique_videos) {
  
  # Filter data for the current video file
  video_data <- sample_data %>% filter(video_recording == video, !is.na(subject))
  # Create the plot for the current video
  raw_data_plot <- ggplot(data = video_data, aes(x = time_frame, y = LEFT_pupil.inter2)) +
    ylab("Pupil size") +
    xlab("Time (in ms)") +
    geom_point(alpha = 0.3, size = 0.4, color = "darkorange") +
    geom_point(aes(y = RIGHT_pupil.inter2), alpha = 0.3, size = 0.4, color = "dodgerblue") +
    geom_point(aes(y = pupil.inter2), alpha = 0.2, size = 0.2, color = "darkgreen") +
    facet_wrap(~ subject, ncol = 8, nrow = 5) +   # 8 columns, 5 rows
    theme_bw() +
    scale_color_manual(values=c("darkorange", "dodgerblue")) +
    scale_fill_manual(values=c("darkorange", "dodgerblue")) +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.y = element_blank(),
          legend.title = element_blank(), 
          legend.position = "top", 
          legend.text = element_text(size = 12))
  
  # Save the plot
  ggsave(filename = paste0("graphs/chimp_data/01_blinkcorrected_interpolated/", video, "_pupil_blinkcorrected_interpolated.png"), plot = raw_data_plot, width = 24, height = 14, units = "cm", scale =1.2)
}
#run if does not work: options(bitmapType='cairo') 

```

```{r}
sample_data<-read_parquet("data/PET1_chimp_Ngamba_MAD8.parquet")
```
#### Baseline correction
```{r}
# baseline
data.pupil.base <- sample_data %>%
  filter(time_frame < IP_test_event_start &
           time_frame >= (IP_test_event_start - 3000)) %>%
  group_by(RECORDING_SESSION_LABEL,
           subject,
           video_file,
           experiment,
           version,
           condition, trial) %>%
  summarise(
    median.base.pupil.left = median(LEFT_pupil.inter2, na.rm = TRUE),
    median.base.pupil.right = median(RIGHT_pupil.inter2, na.rm = TRUE),
    median.base.pupil = median(RIGHT_pupil.inter2, na.rm = TRUE)
  )
```

```{r}
data.pupil.basecorrected <- sample_data %>%
  filter(time_frame > IP_test_event_start &
           time_frame <= (IP_test_event_start + 6000)) %>%
  select(
    RECORDING_SESSION_LABEL ,
    subject,
    video_file,
    experiment,
    condition,
    version,
    trial, 
    video_recording,
    time_frame,
    LEFT_pupil.inter2,
    RIGHT_pupil.inter2,
    pupil.inter2,
    RIGHT_PUPIL_SIZE, LEFT_PUPIL_SIZE, Pupil_diameter_filtered,
    RIGHT_GAZE_X, RIGHT_GAZE_Y, 
    LEFT_GAZE_X, LEFT_GAZE_Y, 
  ) %>%
  group_by(RECORDING_SESSION_LABEL ,
           subject,
           video_file,
           experiment,
           condition,
           version) %>%
  full_join(data.pupil.base) %>% #add baseline data
  mutate(
    LEFT.pupil.base.corrected = as.numeric(
      ifelse(
        !is.na(LEFT_pupil.inter2),
        LEFT_pupil.inter2 / median.base.pupil.left,
        NA
      )
    ),
    RIGHT.pupil.base.corrected = as.numeric(
      ifelse(
        !is.na(RIGHT_pupil.inter2),
        RIGHT_pupil.inter2 / median.base.pupil.right,
        NA
      )
    ),
        pupil.base.corrected = as.numeric(
      ifelse(
        !is.na(pupil.inter2),
        pupil.inter2 / median.base.pupil,
        NA
      )
    )
  ) %>% #subtractive baseline correction
  ungroup()
```
*left pupil
```{r eval=FALSE}
puphist_l <- ggplot(data.pupil.basecorrected, aes(x = LEFT.pupil.base.corrected)) + geom_histogram(aes(y = ..count..), 
    colour = "green", binwidth = 0.5)  + 
    xlab("Left Pupil Size") + ylab("Count") + theme_bw() 
puphist_l
```
*right pupil
```{r eval=FALSE}
puphist_r <- ggplot(data.pupil.basecorrected, aes(x = RIGHT.pupil.base.corrected)) + geom_histogram(aes(y = ..count..), 
    colour = "green", binwidth = 0.5)  + 
    xlab("RIGHT Pupil Size") + ylab("Count") + theme_bw()
puphist_r
```


```{r}
data.pupil.basecorrected <- data.pupil.basecorrected %>%
  mutate(
    RIGHT.pupil.bc.filter = as.numeric(
      ifelse(
        RIGHT.pupil.base.corrected < 1500 |
          RIGHT.pupil.base.corrected > -1500,
        RIGHT.pupil.base.corrected,
        NA
      )
    ),
    LEFT.pupil.bc.filter = as.numeric(
      ifelse(
        LEFT.pupil.base.corrected < 1500 |
          LEFT.pupil.base.corrected > -1500,
        LEFT.pupil.base.corrected,
        NA
      )
    ),
    pupil.bc.filter = as.numeric(
      ifelse(
        pupil.base.corrected < 1500 |
          pupil.base.corrected > -1500,
        pupil.base.corrected,
        NA
      )
    )
  )
```


* Plotting of baseline corrected and filtered data


```{r}

# Loop through each level of video_file
unique_videos <- unique(data.pupil.basecorrected$video_recording)

for (video in unique_videos) {
  
  # Filter data for the current video file
  video_data <- data.pupil.basecorrected %>% filter(video_recording == video, !is.na(subject))
  
  # Create the plot for the current video
  raw_data_plot <- ggplot(data = video_data, aes(x = time_frame, y = LEFT.pupil.bc.filter)) +
    ylab("Pupil size") +
    xlab("Time (in ms)") +
    geom_point(alpha = 0.3, size = 0.4, color = "darkorange") +
    geom_point(aes(y = RIGHT.pupil.bc.filter), alpha = 0.3, size = 0.4, color = "dodgerblue") +
    geom_point(aes(y = pupil.bc.filter), alpha = 0.2, size = 0.2, color = "darkgreen") +
    facet_wrap(~ subject, ncol = 8, nrow = 5) +   # 8 columns, 5 rows
    theme_bw() +
    scale_color_manual(values=c("darkorange", "dodgerblue")) +
    scale_fill_manual(values=c("darkorange", "dodgerblue")) +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.y = element_blank(),
          legend.title = element_blank(), 
          legend.position = "top", 
          legend.text = element_text(size = 12))
  
  # Save the plot
  ggsave(filename = paste0("graphs/chimp_data/02_bc_filtered/", video, "_pupil_bc_filtered.png"), plot = raw_data_plot, width = 24, height = 14, units = "cm", scale =1.2)
}
#run if does not work: options(bitmapType='cairo') 

```


```{r}

# Loop through each level of video_file
unique_videos <- unique(data.pupil.basecorrected$video_recording)

for (video in unique_videos) {
  
  # Filter data for the current video file
  video_data <- data.pupil.basecorrected %>% filter(video_recording == video, !is.na(subject))
  
  # Create the plot for the current video
  raw_data_plot <- ggplot(data = video_data, aes(x = time_frame, y = LEFT.pupil.base.corrected)) +
    ylab("Pupil size") +
    xlab("Time (in ms)") +
    geom_point(alpha = 0.3, size = 0.4, color = "darkorange") +
    geom_point(aes(y = RIGHT.pupil.base.corrected), alpha = 0.3, size = 0.4, color = "dodgerblue") +
    geom_point(aes(y = pupil.base.corrected), alpha = 0.2, size = 0.2, color = "darkgreen") +
    facet_wrap(~ subject, ncol = 8, nrow = 5) +   # 8 columns, 5 rows
    theme_bw() +
    scale_color_manual(values=c("darkorange", "dodgerblue")) +
    scale_fill_manual(values=c("darkorange", "dodgerblue")) +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.y = element_blank(),
          legend.title = element_blank(), 
          legend.position = "top", 
          legend.text = element_text(size = 12))
  
  # Save the plot
  ggsave(filename = paste0("graphs/chimp_data/02_bc_not_filtered/", video, "_pupil_bc.png"), plot = raw_data_plot, width = 24, height = 14, units = "cm", scale =1.2)
}
#run if does not work: options(bitmapType='cairo') 

```


```{r}
write_parquet(sample_data, "data/PET1_chimp_Ngamba_MAD8.parquet")
```




#### Downsampling
```{r}
data.pupil.basecorrected <- data.pupil.basecorrected %>%
  mutate(bin = cut(time_frame, seq(min(time_frame), max(time_frame), 100), right = FALSE)) %>% #addition of time bins (100 ms = 10 hz)
  separate(bin,
           c("bin_low", "bin_high"),
           sep = ",",
           remove = FALSE) %>%
  select(-bin_high, -bin) %>%
  mutate(bin_low = as.numeric(str_replace_all(bin_low, "\\[|\\]", "")))

data.pupil.basecorrected.downsampled <-
  data.pupil.basecorrected %>%
  group_by(RECORDING_SESSION_LABEL ,
           subject,
           video_file,
           experiment,
           condition,
           version, trial,video_recording,
           bin_low) %>%
  summarise(
    LEFT.pupil.base.corrected = median(LEFT.pupil.base.corrected, na.rm=TRUE),
    RIGHT.pupil.base.corrected = median(RIGHT.pupil.base.corrected, , na.rm=TRUE),
    pupil.base.corrected = median(pupil.base.corrected, , na.rm=TRUE),
    Xgaze_LEFT = median(LEFT_GAZE_X, na.rm=TRUE), 
    Ygaze_LEFT = median(LEFT_GAZE_Y, na.rm=TRUE), 
    Xgaze_RIGHT = median(RIGHT_GAZE_X, na.rm=TRUE), 
    Ygaze_RIGHT = median(RIGHT_GAZE_Y, na.rm=TRUE) 
  )
```



```{r}


# Loop through each level of video_file
unique_videos <- unique(data.pupil.basecorrected.downsampled$video_recording)

for (video in unique_videos) {
  
  # Filter data for the current video file
  video_data <- data.pupil.basecorrected.downsampled %>% filter(video_recording == video, !is.na(subject))
  
  # Create the plot for the current video
  raw_data_plot <- ggplot(data = video_data, aes(x = bin_low, y = LEFT.pupil.base.corrected)) +
    ylab("Pupil size") +
    xlab("Time (in ms)") +
    geom_point(alpha = 0.6, size = 0.5, color = "darkorange") +
    geom_point(aes(y = RIGHT.pupil.base.corrected), alpha = 0.6, size = 0.5, color = "dodgerblue") +
    geom_point(aes(y = pupil.base.corrected), alpha = 0.4, size = 0.3, color = "darkgreen") +
    facet_wrap(~ subject, ncol = 8, nrow = 5) +   # 8 columns, 5 rows
    theme_bw() +
    scale_color_manual(values=c("darkorange", "dodgerblue")) +
    scale_fill_manual(values=c("darkorange", "dodgerblue")) +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.y = element_blank(),
          legend.title = element_blank(), 
          legend.position = "top", 
          legend.text = element_text(size = 12))
  
  # Save the plot
  ggsave(filename = paste0("graphs/chimp_data/03_bc_ds/", video, "_pupil_bc_ds.png"), plot = raw_data_plot, width = 24, height = 14, units = "cm", scale =1.2)
}
#run if does not work: options(bitmapType='cairo') 

```


#### Additional filtebased on speed with downsampled data
```{r}
data.pupil.basecorrected.downsampled <-
  data.pupil.basecorrected.downsampled %>%
  mutate(
    speed_left_pupil = speed_pupil(LEFT.pupil.base.corrected, bin_low),
    speed_right_pupil = speed_pupil(RIGHT.pupil.base.corrected, bin_low),
    speed_pupil = speed_pupil(pupil.base.corrected, bin_low),
    MAD_left_pupil = calc_mad(speed_left_pupil, n = 8),
    MAD_right_pupil = calc_mad(speed_right_pupil, n = 8),
    MAD_pupil = calc_mad(speed_pupil, n = 8),
    LEFT_pupil.ds.noArtefact = as.numeric(
      ifelse(
        speed_left_pupil < MAD_left_pupil,
        LEFT.pupil.base.corrected,
        NA
      )
    ),
    RIGHT_pupil.ds.noArtefact = as.numeric(
      ifelse(
        speed_right_pupil < MAD_right_pupil,
        RIGHT.pupil.base.corrected,
        NA
      )
    ),
    pupil.ds.noArtefact = as.numeric(
      ifelse(
        speed_pupil < MAD_pupil,
        pupil.base.corrected,
        NA
      )
    ),
    LEFT_pupil.ds.inter = na.approx(
      LEFT_pupil.ds.noArtefact,
      na.rm = FALSE,
      maxgap = 100
    ),
    RIGHT_pupil.ds.inter = na.approx(
      RIGHT_pupil.ds.noArtefact,
      na.rm = FALSE,
      maxgap = 100
    ),
    pupil.ds.inter = na.approx(
      pupil.ds.noArtefact,
      na.rm = FALSE,
      maxgap = 100
    )
  )

```





```{r}
write_parquet(data.pupil.basecorrected.downsampled,  "data/PET1_chimp_Ngamba_basecorrected_downsampled.parquet")
```



```{r}


# Loop through each level of video_file
unique_videos <- unique(data.pupil.basecorrected.downsampled$video_recording)

for (video in unique_videos) {
  
  # Filter data for the current video file
  video_data <- data.pupil.basecorrected.downsampled %>% filter(video_recording == video, !is.na(subject))
  
  # Create the plot for the current video
  raw_data_plot <- ggplot(data = video_data, aes(x = bin_low, y = LEFT_pupil.ds.inter)) +
    ylab("Pupil size") +
    xlab("Time (in ms)") +
    geom_point(alpha = 0.6, size = 0.5, color = "darkorange") +
    geom_point(aes(y = RIGHT_pupil.ds.inter), alpha = 0.6, size = 0.5, color = "dodgerblue") +
      geom_point(aes(y = pupil.ds.inter), alpha = 0.4, size = 0.3, color = "darkgreen") +
    facet_wrap(~ subject, ncol = 8, nrow = 5) +   # 8 columns, 5 rows
    theme_bw() +
    scale_color_manual(values=c("darkorange", "dodgerblue")) +
    scale_fill_manual(values=c("darkorange", "dodgerblue")) +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.y = element_blank(),
          legend.title = element_blank(), 
          legend.position = "top", 
          legend.text = element_text(size = 12))
  
  # Save the plot
  ggsave(filename = paste0("graphs/chimp_data/04_bc_ds_ac/", video, "_pupil_bc_ds_ac.png"), plot = raw_data_plot, width = 24, height = 14, units = "cm", scale =1.2)
}
#run if does not work: options(bitmapType='cairo') 

```

### Proportion data available

```{r}
prop_pupil_data_available <- data.pupil.basecorrected.downsampled %>%
  group_by(
    RECORDING_SESSION_LABEL ,
    subject,
    video_file,
    experiment,
    condition,
    version,
    trial,
    video_recording
  ) %>%
  summarise(
    prop_pupil_data_left = sum(!is.na(LEFT_pupil.ds.inter)) / (6100 / 100),
    prop_pupil_data_right = sum(!is.na(RIGHT_pupil.ds.inter)) /
      (4100 / 100),
    prop_pupil_data = sum(!is.na(pupil.ds.inter)) / (6100 / 100)
  )


filter_trials <- prop_pupil_data_available %>%
  filter(prop_pupil_data<0.7)%>%
  select(-prop_pupil_data_left, -prop_pupil_data_right, prop_pupil_data)
```

### Group level plot

```{r}
data.pupil.basecorrected.downsampled<-read_parquet("data/PET1_chimp_Ngamba_basecorrected_downsampled.parquet")
```


*Aggregate data

```{r}

data.pupil.basecorrected.downsampled.agg <-
  data.pupil.basecorrected.downsampled %>%
  filter(!is.na(subject)) %>%
  anti_join(filter_trials) %>%
  group_by(bin_low, video_file, experiment, version, condition) %>%
  summarise(
    mean.pupil.corrected.binned.right = mean(RIGHT_pupil.ds.inter, na.rm = TRUE),
    sd.pupil.corrected.binned.right = sd(RIGHT_pupil.ds.inter, na.rm = TRUE),
    se.pupil.corrected.binned.right = sd(RIGHT_pupil.ds.inter, na.rm = TRUE) / sqrt(length(RIGHT_pupil.ds.inter)),
    mean.pupil.corrected.binned.left = mean(LEFT_pupil.ds.inter, na.rm = TRUE),
    sd.pupil.corrected.binned.left = sd(LEFT_pupil.ds.inter, na.rm = TRUE),
    se.pupil.corrected.binned.left = sd(LEFT_pupil.ds.inter, na.rm = TRUE) / sqrt(length(LEFT_pupil.ds.inter)),
    mean.pupil.corrected.binned = mean(pupil.ds.inter, na.rm = TRUE),
    sd.pupil.corrected.binned = sd(pupil.ds.inter, na.rm = TRUE),
    se.pupil.corrected.binned = sd(pupil.ds.inter, na.rm = TRUE) / sqrt(length(pupil.ds.inter))
  )%>%
  ungroup()%>%
  mutate(exp_ver = paste0(experiment,"_",  version))

```

* Plot group level data
right pupil
```{r}

# Loop through each level of video_file
unique_exp <-
  unique(paste(data.pupil.basecorrected.downsampled.agg$exp_ver))

for (exp in unique_exp) {
  # Filter data for the current video file
  exp_data <-
    data.pupil.basecorrected.downsampled.agg %>% filter(exp_ver == exp, !is.na(exp_ver))
  
  # Create the plot for the current video
  agg_data_plot <-
    ggplot(data = exp_data,
           aes(x = bin_low, y = mean.pupil.corrected.binned.right)) +
    # geom_vline(aes(xintercept = baseline.end),
    #            lty = 2,
    #            alpha = 0.3) +
    ylab("Pupil size") +
    xlab("Time (in ms)") +
    geom_point(
      aes(x = bin_low, y = mean.pupil.corrected.binned.right, color = condition),
      alpha = 0.3,
      size = 0.5
    ) +
    geom_ribbon(
      aes(
        ymin = mean.pupil.corrected.binned.right - se.pupil.corrected.binned.right,
        ymax = mean.pupil.corrected.binned.right + se.pupil.corrected.binned.right,
        fill = condition
      ),
      alpha = 0.3
    ) +
    #   xlim(0, 8000) +
    theme_bw() +
    scale_color_manual(values = c("darkorange", "dodgerblue")) +
    scale_fill_manual(values = c("darkorange", "dodgerblue")) +
    theme(
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank(),
      panel.grid.major.y = element_blank(),
      panel.grid.minor.y = element_blank(),
      legend.title = element_blank(),
      legend.position = "top",
      legend.text = element_text(size = 12),
      legend.key = element_blank(),
      legend.background = element_rect(fill = "transparent")
    )
  
  # Save the plot
  ggsave(
    filename = paste0("graphs/chimp_data/", exp, "_right_pupil_group.png"),
    plot = agg_data_plot,
    width = 16,
    height = 9,
    units = "cm",
    scale = 0.8
  )
}
#run if does not work: options(bitmapType='cairo')

```


left pupil 
```{r}

# Loop through each level of video_file
unique_exp <-
  unique(paste(data.pupil.basecorrected.downsampled.agg$exp_ver))

for (exp in unique_exp) {
  # Filter data for the current video file
  exp_data <-
    data.pupil.basecorrected.downsampled.agg %>% filter(exp_ver == exp, !is.na(exp_ver))
  
  # Create the plot for the current video
  agg_data_plot <-
    ggplot(data = exp_data,
           aes(x = bin_low, y = mean.pupil.corrected.binned.left)) +
    # geom_vline(aes(xintercept = baseline.end),
    #            lty = 2,
    #            alpha = 0.3) +
    ylab("Pupil size") +
    xlab("Time (in ms)") +
    geom_point(
      aes(x = bin_low, y = mean.pupil.corrected.binned.left, color = condition),
      alpha = 0.3,
      size = 0.5
    ) +
    geom_ribbon(
      aes(
        ymin = mean.pupil.corrected.binned.left - se.pupil.corrected.binned.left,
        ymax = mean.pupil.corrected.binned.left + se.pupil.corrected.binned.left,
        fill = condition
      ),
      alpha = 0.3
    ) +
    #   xlim(0, 8000) +
    theme_bw() +
    scale_color_manual(values = c("darkorange", "dodgerblue")) +
    scale_fill_manual(values = c("darkorange", "dodgerblue")) +
    theme(
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank(),
      panel.grid.major.y = element_blank(),
      panel.grid.minor.y = element_blank(),
      legend.title = element_blank(),
      legend.position = "top",
      legend.text = element_text(size = 12),
      legend.key = element_blank(),
      legend.background = element_rect(fill = "transparent")
    )
  
  # Save the plot
  ggsave(
    filename = paste0("graphs/chimp_data/", exp, "_left_pupil_group.png"),
    plot = agg_data_plot,
    width = 16,
    height = 9,
    units = "cm",
    scale = 0.8
  )
}
#run if does not work: options(bitmapType='cairo')

```

combined pupil
left pupil 
```{r}

# Loop through each level of video_file
unique_exp <-
  unique(paste(data.pupil.basecorrected.downsampled.agg$exp_ver))

for (exp in unique_exp) {
  # Filter data for the current video file
  exp_data <-
    data.pupil.basecorrected.downsampled.agg %>% filter(exp_ver == exp, !is.na(exp_ver))
  
  # Create the plot for the current video
  agg_data_plot <-
    ggplot(data = exp_data,
           aes(x = bin_low, y = mean.pupil.corrected.binned)) +
    # geom_vline(aes(xintercept = baseline.end),
    #            lty = 2,
    #            alpha = 0.3) +
    ylab("Pupil size") +
    xlab("Time (in ms)") +
    geom_point(
      aes(x = bin_low, y = mean.pupil.corrected.binned, color = condition),
      alpha = 0.3,
      size = 0.5
    ) +
    geom_ribbon(
      aes(
        ymin = mean.pupil.corrected.binned - se.pupil.corrected.binned,
        ymax = mean.pupil.corrected.binned + se.pupil.corrected.binned,
        fill = condition
      ),
      alpha = 0.3
    ) +
    #   xlim(0, 8000) +
    theme_bw() +
    scale_color_manual(values = c("darkorange", "dodgerblue")) +
    scale_fill_manual(values = c("darkorange", "dodgerblue")) +
    theme(
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank(),
      panel.grid.major.y = element_blank(),
      panel.grid.minor.y = element_blank(),
      legend.title = element_blank(),
      legend.position = "top",
      legend.text = element_text(size = 12),
      legend.key = element_blank(),
      legend.background = element_rect(fill = "transparent")
    )
  
  # Save the plot
  ggsave(
    filename = paste0("graphs/chimp_data/", exp, "_pupil_group.png"),
    plot = agg_data_plot,
    width = 16,
    height = 9,
    units = "cm",
    scale = 0.8
  )
}
#run if does not work: options(bitmapType='cairo')

```


